{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6212a897-1a14-4981-b8ee-d41aa3f6a665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\lenovo\\.cache\\kagglehub\\datasets\\nih-chest-xrays\\data\\versions\\3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nih-chest-xrays/data\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48741e4-1418-49d6-91b6-78bf2b33049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: C:/Users/lenovo/.cache/kagglehub/datasets/nih-chest-xrays/data/versions/3\n",
      "Folders in dataset: ['ARXIV_V5_CHESTXRAY.pdf', 'BBox_List_2017.csv', 'Data_Entry_2017.csv', 'FAQ_CHESTXRAY.pdf', 'images_001', 'images_002', 'images_003', 'images_004', 'images_005', 'images_006', 'images_007', 'images_008', 'images_009', 'images_010', 'images_011', 'images_012', 'LOG_CHESTXRAY.pdf', 'README_CHESTXRAY.pdf', 'test_list.txt', 'train_val_list.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the dataset (replace with your path)\n",
    "data_path = 'C:/Users/lenovo/.cache/kagglehub/datasets/nih-chest-xrays/data/versions/3'\n",
    "print(\"Dataset path:\", data_path)\n",
    "\n",
    "# Check the directory structure\n",
    "folders = os.listdir(data_path)\n",
    "print(\"Folders in dataset:\", folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3922875e-ddfe-4972-8f70-5b7b2fefa35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files in the dataset: ['BBox_List_2017.csv', 'Data_Entry_2017.csv']\n",
      "        Image Index Finding Label     Bbox [x           y           w  \\\n",
      "0  00013118_008.png   Atelectasis  225.084746  547.019217   86.779661   \n",
      "1  00014716_007.png   Atelectasis  686.101695  131.543498  185.491525   \n",
      "2  00029817_009.png   Atelectasis  221.830508  317.053115  155.118644   \n",
      "3  00014687_001.png   Atelectasis  726.237288  494.951420  141.016949   \n",
      "4  00017877_001.png   Atelectasis  660.067797  569.780787  200.677966   \n",
      "\n",
      "           h]  Unnamed: 6  Unnamed: 7  Unnamed: 8  \n",
      "0   79.186441         NaN         NaN         NaN  \n",
      "1  313.491525         NaN         NaN         NaN  \n",
      "2  216.949153         NaN         NaN         NaN  \n",
      "3   55.322034         NaN         NaN         NaN  \n",
      "4   78.101695         NaN         NaN         NaN  \n",
      "Total records: 984\n"
     ]
    }
   ],
   "source": [
    "# Look for any CSV files that might contain labels or metadata\n",
    "csv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
    "print(\"CSV files in the dataset:\", csv_files)\n",
    "\n",
    "# If a CSV file is found, you can load it and inspect the data\n",
    "if csv_files:\n",
    "    csv_file = os.path.join(data_path, csv_files[0])\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(df.head())  # Display the first few rows\n",
    "    print(f\"Total records: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a2cede-72fc-458b-a28a-54711a6e16ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Label\n",
      "Atelectasis     180\n",
      "Effusion        153\n",
      "Cardiomegaly    146\n",
      "Infiltrate      123\n",
      "Pneumonia       120\n",
      "Pneumothorax     98\n",
      "Mass             85\n",
      "Nodule           79\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Finding Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2094bf6-7809-4edd-aef3-cee9bfca99a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112120 image files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the dataset\n",
    "data_path = 'C:/Users/lenovo/.cache/kagglehub/datasets/nih-chest-xrays/data/versions/3'\n",
    "image_folders = [f'images_{i:03d}' for i in range(1, 13)]  # Generating folder names like images_001, images_002, etc.\n",
    "\n",
    "# List to store image file paths\n",
    "image_paths = []\n",
    "\n",
    "# Collect image paths from all subfolders\n",
    "for folder in image_folders:\n",
    "    folder_path = os.path.join(data_path, folder, 'images')\n",
    "    \n",
    "    if os.path.isdir(folder_path):  # Check if the folder exists\n",
    "        images = os.listdir(folder_path)\n",
    "        image_paths.extend([os.path.join(folder_path, img) for img in images])\n",
    "\n",
    "print(f\"Found {len(image_paths)} image files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e7e94d-1fd1-4689-8bfd-57f60eb2b158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid images found: 100 out of 100\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Validate a subset of image paths\n",
    "valid_image_paths = []\n",
    "for img_path in image_paths[:100]:  # Check the first 100 paths (or all if needed)\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        img.verify()  # Ensure the file is a valid image\n",
    "        valid_image_paths.append(img_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid image file: {img_path}, Error: {e}\")\n",
    "\n",
    "print(f\"Valid images found: {len(valid_image_paths)} out of {len(image_paths[:100])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4484a5-d3bc-4342-ae1a-f337b36aceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of preprocessed images: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 224  # Resize dimensions\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).resize((IMG_SIZE, IMG_SIZE))\n",
    "        img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {image_path}, Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage: Preprocess the first 10 images\n",
    "preprocessed_images = [preprocess_image(img_path) for img_path in image_paths[:10]]\n",
    "preprocessed_images = [img for img in preprocessed_images if img is not None]  # Remove None values\n",
    "print(f\"Number of preprocessed images: {len(preprocessed_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7376dfd6-e8e5-45db-8a38-6727da3b5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the dataset directory\n",
    "data_path = 'C:/Users/lenovo/.cache/kagglehub/datasets/nih-chest-xrays/data/versions/3'\n",
    "\n",
    "# List all files in the dataset directory\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c2f0c4-3ca2-4ac6-a6ff-d046d78e4100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
      "0  00000001_000.png            Cardiomegaly            0           1   \n",
      "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
      "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
      "3  00000002_000.png              No Finding            0           2   \n",
      "4  00000003_000.png                  Hernia            0           3   \n",
      "\n",
      "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
      "0           58              M            PA                 2682     2749   \n",
      "1           58              M            PA                 2894     2729   \n",
      "2           58              M            PA                 2500     2048   \n",
      "3           81              M            PA                 2500     2048   \n",
      "4           81              F            PA                 2582     2991   \n",
      "\n",
      "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
      "0                        0.143  0.143          NaN  \n",
      "1                        0.143  0.143          NaN  \n",
      "2                        0.168  0.168          NaN  \n",
      "3                        0.171  0.171          NaN  \n",
      "4                        0.143  0.143          NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = 'C:/Users/lenovo/.cache/kagglehub/datasets/nih-chest-xrays/data/versions/3/Data_Entry_2017.csv'\n",
    "\n",
    "# Load the CSV into a pandas dataframe\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce3b8d5e-eb7f-443a-b0d3-e336d7e3bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Get unique labels in the 'Finding Labels' column\n",
    "print(\"Unique labels:\\n\", df['Finding Labels'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "199841f6-7b88-4f0e-a6f8-cfe28dcb6b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
       "0                        0.143  0.143          NaN  \n",
       "1                        0.143  0.143          NaN  \n",
       "2                        0.168  0.168          NaN  \n",
       "3                        0.171  0.171          NaN  \n",
       "4                        0.143  0.143          NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c726bea-4d63-4409-ab77-047c7789988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image Index', 'Finding Labels', 'Follow-up #', 'Patient ID', 'Patient Age', 'Patient Gender', 'View Position', 'OriginalImage[Width', 'Height]', 'OriginalImagePixelSpacing[x', 'y]', 'Unnamed: 11']\n"
     ]
    }
   ],
   "source": [
    "# List of column names\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the column names\n",
    "print(column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93aa3f28-1f2e-4e2d-b781-dff1970e4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['Unnamed: 11', 'Follow-up #', 'Patient ID', 'OriginalImage[Width','Height]', 'OriginalImagePixelSpacing[x', 'y]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fdd351c-505d-4743-ac64-df705714ade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Image Index  Patient Age Patient Gender View Position  Atelectasis  \\\n",
      "0  00000001_000.png           58              M            PA            0   \n",
      "1  00000001_001.png           58              M            PA            0   \n",
      "2  00000001_002.png           58              M            PA            0   \n",
      "3  00000002_000.png           81              M            PA            0   \n",
      "4  00000003_000.png           81              F            PA            0   \n",
      "\n",
      "   Cardiomegaly  Consolidation  Edema  Effusion  Emphysema  Fibrosis  Hernia  \\\n",
      "0             1              0      0         0          0         0       0   \n",
      "1             1              0      0         0          1         0       0   \n",
      "2             1              0      0         1          0         0       0   \n",
      "3             0              0      0         0          0         0       0   \n",
      "4             0              0      0         0          0         0       1   \n",
      "\n",
      "   Infiltration  Mass  No Finding  Nodule  Pleural_Thickening  Pneumonia  \\\n",
      "0             0     0           0       0                   0          0   \n",
      "1             0     0           0       0                   0          0   \n",
      "2             0     0           0       0                   0          0   \n",
      "3             0     0           1       0                   0          0   \n",
      "4             0     0           0       0                   0          0   \n",
      "\n",
      "   Pneumothorax  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Initialize the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Convert the 'Finding Labels' column into a list of labels\n",
    "labels = df['Finding Labels'].str.split('|')\n",
    "\n",
    "# Fit and transform the labels\n",
    "binary_labels = mlb.fit_transform(labels)\n",
    "\n",
    "# Create a new DataFrame for the binary encoded labels\n",
    "binary_labels_df = pd.DataFrame(binary_labels, columns=mlb.classes_)\n",
    "\n",
    "# Concatenate the binary labels with the original dataframe (excluding the 'Finding Labels' column)\n",
    "df = pd.concat([df.drop('Finding Labels', axis=1), binary_labels_df], axis=1)\n",
    "\n",
    "# Show the first few rows to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66ee6cae-059b-4bf5-af57-01470bba5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "# Label Encoding for 'Patient Gender'\n",
    "le_gender = LabelEncoder()\n",
    "df['Patient Gender'] = le_gender.fit_transform(df['Patient Gender'])\n",
    "\n",
    "# One-Hot Encoding for 'View Position'\n",
    "df = pd.get_dummies(df, columns=['View Position'], drop_first=True)\n",
    "\n",
    "# Standard Scaling for 'Patient Age'\n",
    "scaler = StandardScaler()\n",
    "df['Patient Age'] = scaler.fit_transform(df[['Patient Age']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f948bfe-9716-48b1-95ba-a973737f2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Image Index', 'Patient Age', 'Patient Gender', 'Atelectasis',\n",
      "       'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema',\n",
      "       'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule',\n",
      "       'Pleural_Thickening', 'Pneumonia', 'Pneumothorax', 'View Position_PA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the final columns\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f23d0a67-09a2-469e-90b9-56dcd454f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224  # Resize dimensions\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).resize((IMG_SIZE, IMG_SIZE))\n",
    "        img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {img_path}, Error: {e}\")\n",
    "        return None\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d88afff-dc84-43f7-b12d-209c9bdedeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (4999, 224, 224, 3)\n",
      "Labels shape: (4999, 15)\n",
      "Train Images: (3999, 224, 224, 3), Train Labels: (3999, 15)\n",
      "Test Images: (1000, 224, 224, 3), Test Labels: (1000, 15)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Path to the dataset directory and CSV file\n",
    "# Path to the image directory\n",
    "image_directory = 'C:/Users/lenovo/.cache/kagglehub/datasets/nih-chest-xrays/data/versions/3/images_001/images'\n",
    "\n",
    "# Filter the dataset to include only images available in the directory\n",
    "available_images = set(os.listdir(image_directory))\n",
    "df = df[df['Image Index'].isin(available_images)]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "labels_columns = df.columns[4:]  # Assuming first 4 columns are non-label data\n",
    "df_labels = df[labels_columns].astype(np.float32)\n",
    "labels = df_labels.values\n",
    "\n",
    "# Prepare image paths and preprocess images\n",
    "image_paths = df['Image Index'].tolist()\n",
    "images = []\n",
    "\n",
    "for img_name in image_paths:\n",
    "    img_path = os.path.join(image_directory, img_name)\n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        img = load_img(img_path, target_size=(224, 224))\n",
    "        img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "        images.append(img_array)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {img_path}\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure consistency between images and labels\n",
    "if images.shape[0] != labels.shape[0]:\n",
    "    raise ValueError(\"Mismatch between number of images and labels.\")\n",
    "\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, train_size=0.8, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train Images: {train_images.shape}, Train Labels: {train_labels.shape}\")\n",
    "print(f\"Test Images: {test_images.shape}, Test Labels: {test_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6aa53ed-e4ab-4be6-92fa-bdc9ec8791c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(15, activation='sigmoid')  # 15 labels; sigmoid for multi-label classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cbac4f1-0612-4794-8077-f7d19200ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Use a pre-trained model (EfficientNetB0)\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(15, activation='sigmoid')(x)  # Multi-label classification\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze base model layers for transfer learning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3041564d-5df1-43a7-ae8a-e65d60eae802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow(train_images, train_labels, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b657c768-ffba-46f9-83f2-0faf60e7fa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights for each label: {0: {np.float32(0.0): np.float64(0.5213734415198892), np.float32(1.0): np.float64(12.19675925925926)}, 1: {np.float32(0.0): np.float64(0.520240916271722), np.float32(1.0): np.float64(12.851219512195122)}, 2: {np.float32(0.0): np.float64(0.5086889360880479), np.float32(1.0): np.float64(29.272222222222222)}, 3: {np.float32(0.0): np.float64(0.5520746018440905), np.float32(1.0): np.float64(5.300804828973843)}, 4: {np.float32(0.0): np.float64(0.5121500777604977), np.float32(1.0): np.float64(21.076)}, 5: {np.float32(0.0): np.float64(0.5178887359937094), np.float32(1.0): np.float64(14.475274725274724)}, 6: {np.float32(0.0): np.float64(0.5298672566371682), np.float32(1.0): np.float64(8.87037037037037)}, 7: {np.float32(0.0): np.float64(0.600250626566416), np.float32(1.0): np.float64(2.99375)}, 8: {np.float32(0.0): np.float64(0.5177869496855346), np.float32(1.0): np.float64(14.55524861878453)}, 9: {np.float32(0.0): np.float64(1.0475149105367794), np.float32(1.0): np.float64(0.9566085693536674)}, 10: {np.float32(0.0): np.float64(0.5211671612265084), np.float32(1.0): np.float64(12.310747663551401)}, 11: {np.float32(0.0): np.float64(0.5161637931034483), np.float32(1.0): np.float64(15.966666666666667)}, 12: {np.float32(0.0): np.float64(0.5062451960030746), np.float32(1.0): np.float64(40.53076923076923)}, 13: {np.float32(0.0): np.float64(0.5196252465483234), np.float32(1.0): np.float64(13.238693467336683)}, 14: {np.float32(0.0): np.float64(1.5415447630193095), np.float32(1.0): np.float64(0.7400280898876405)}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights for each label\n",
    "class_weights_dict = {}\n",
    "\n",
    "for i in range(labels.shape[1]):  # Iterate over each class\n",
    "    y = labels[:, i]  # Binary labels for class i\n",
    "    unique_classes = np.unique(y)  # Ensure unique classes (0 and 1)\n",
    "    \n",
    "    if len(unique_classes) > 1:  # To avoid errors for classes with only one value\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=unique_classes,\n",
    "            y=y\n",
    "        )\n",
    "        class_weights_dict[i] = {unique_classes[0]: class_weights[0], unique_classes[1]: class_weights[1]}\n",
    "    else:\n",
    "        print(f\"Skipping class {i}, only one class present.\")\n",
    "\n",
    "print(\"Class weights for each label:\", class_weights_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "569229d3-a243-4715-964d-0906eb2a8f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset size: 5099\n"
     ]
    }
   ],
   "source": [
    "# Find indices of underrepresented samples\n",
    "minority_class_indices = np.where(labels[:, 6] == 1)[0]  # Example for class 6\n",
    "oversample_indices = np.random.choice(minority_class_indices, size=100, replace=True)  # Oversample\n",
    "\n",
    "# Append oversampled images and labels\n",
    "oversampled_images = np.concatenate([images, images[oversample_indices]], axis=0)\n",
    "oversampled_labels = np.concatenate([labels, labels[oversample_indices]], axis=0)\n",
    "\n",
    "print(f\"New dataset size: {oversampled_images.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09700d35-b874-411c-aaec-a85099f65a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset size: 5269\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    shear_range=0.15\n",
    ")\n",
    "\n",
    "# Generate augmented data for the minority class (class 6)\n",
    "minority_class_indices = np.where(labels[:, 6] == 1)[0]\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "for idx in minority_class_indices:\n",
    "    img = images[idx]\n",
    "    label = labels[idx]\n",
    "    for _ in range(10):  # Generate 10 augmented samples per image\n",
    "        augmented_img = datagen.random_transform(img)\n",
    "        augmented_images.append(augmented_img)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "# Append augmented data to the dataset\n",
    "images = np.concatenate([images, np.array(augmented_images)], axis=0)\n",
    "labels = np.concatenate([labels, np.array(augmented_labels)], axis=0)\n",
    "\n",
    "print(f\"Augmented dataset size: {images.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e72089b-6514-4f83-a47c-c56736426dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "\n",
    "# Load ResNet50 model pre-trained on ImageNet\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Add custom layers on top\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "output = Dense(labels.shape[1], activation='sigmoid')(x)  # Multi-label classification\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze base model layers for transfer learning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c5f510c-fc39-4bb7-9abb-947156342680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def weighted_binary_crossentropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        return -tf.reduce_mean(weights[0] * y_true * tf.math.log(y_pred) +\n",
    "                               weights[1] * (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "# Example: Assign weights for imbalance (adjust for your data)\n",
    "positive_weight = 0.9\n",
    "negative_weight = 0.1\n",
    "\n",
    "model.compile(optimizer='adam', loss=weighted_binary_crossentropy([negative_weight, positive_weight]), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ab91777-04e7-4e61-9e40-d153e24ce0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_252']. Received: the structure of inputs=*\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 2s/step - accuracy: 0.1253 - loss: 0.0823 - val_accuracy: 0.0160 - val_loss: 0.0471\n",
      "Epoch 2/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 2s/step - accuracy: 0.0639 - loss: 0.0461 - val_accuracy: 0.0160 - val_loss: 0.0464\n",
      "Epoch 3/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 2s/step - accuracy: 0.1197 - loss: 0.0446 - val_accuracy: 0.0160 - val_loss: 0.0465\n",
      "Epoch 4/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 3s/step - accuracy: 0.1711 - loss: 0.0447 - val_accuracy: 0.0430 - val_loss: 0.0454\n",
      "Epoch 5/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1290s\u001b[0m 10s/step - accuracy: 0.1101 - loss: 0.0440 - val_accuracy: 0.0680 - val_loss: 0.0459\n",
      "Epoch 6/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 3s/step - accuracy: 0.1449 - loss: 0.0445 - val_accuracy: 0.0160 - val_loss: 0.0458\n",
      "Epoch 7/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 3s/step - accuracy: 0.1352 - loss: 0.0435 - val_accuracy: 0.2920 - val_loss: 0.0453\n",
      "Epoch 8/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 3s/step - accuracy: 0.1335 - loss: 0.0444 - val_accuracy: 0.2730 - val_loss: 0.0448\n",
      "Epoch 9/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 3s/step - accuracy: 0.1532 - loss: 0.0429 - val_accuracy: 0.1090 - val_loss: 0.0443\n",
      "Epoch 10/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 10s/step - accuracy: 0.1282 - loss: 0.0434 - val_accuracy: 0.0320 - val_loss: 0.0434\n",
      "Epoch 11/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 3s/step - accuracy: 0.1632 - loss: 0.0429 - val_accuracy: 0.0370 - val_loss: 0.0433\n",
      "Epoch 12/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 4s/step - accuracy: 0.1753 - loss: 0.0427 - val_accuracy: 0.1430 - val_loss: 0.0427\n",
      "Epoch 13/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 4s/step - accuracy: 0.1613 - loss: 0.0440 - val_accuracy: 0.3090 - val_loss: 0.0449\n",
      "Epoch 14/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 4s/step - accuracy: 0.1563 - loss: 0.0423 - val_accuracy: 0.2690 - val_loss: 0.0439\n",
      "Epoch 15/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 4s/step - accuracy: 0.1829 - loss: 0.0417 - val_accuracy: 0.0530 - val_loss: 0.0425\n",
      "Epoch 16/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 3s/step - accuracy: 0.1399 - loss: 0.0419 - val_accuracy: 0.1300 - val_loss: 0.0422\n",
      "Epoch 17/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 3s/step - accuracy: 0.1530 - loss: 0.0411 - val_accuracy: 0.0770 - val_loss: 0.0418\n",
      "Epoch 18/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 2s/step - accuracy: 0.1766 - loss: 0.0423 - val_accuracy: 0.0590 - val_loss: 0.0424\n",
      "Epoch 19/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 2s/step - accuracy: 0.1649 - loss: 0.0420 - val_accuracy: 0.0980 - val_loss: 0.0420\n",
      "Epoch 20/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 2s/step - accuracy: 0.1623 - loss: 0.0417 - val_accuracy: 0.1520 - val_loss: 0.0415\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    shear_range=0.15\n",
    ")\n",
    "\n",
    "# Apply augmentation to train images\n",
    "datagen.fit(train_images)\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db7e69db-8905-42dd-8e68-1472f4d3e0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.1470 - loss: 0.0406\n",
      "Test Loss: 0.04147966951131821\n",
      "Test Accuracy: 0.15199999511241913\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
